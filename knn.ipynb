{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_wWWywc45LkO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import copy\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_distance(a, b):\n",
        "  dist = 0\n",
        "  for i in range(len(a)):\n",
        "    dist += (a[i] - b[i])**2\n",
        "  return np.sqrt(dist)\n",
        "\n",
        "\n",
        "def get_accuracy(X, y):\n",
        "  correct = 0\n",
        "  for i in range(len(X)):\n",
        "    distances = []\n",
        "    for j in range(len(X)):\n",
        "      if i!=j:\n",
        "        distances.append([euclidean_distance(X[i], X[j]), y[j]])\n",
        "    min(distances)\n",
        "    if min(distances)[1] == y[i][0]:\n",
        "      correct += 1\n",
        "  return round((correct/len(X))*100,2)"
      ],
      "metadata": {
        "id": "otY6GK0L9dXd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_selection(data):\n",
        "  cols = [i for i in range(1, len(data.columns))]\n",
        "  absolute_best = (0,None)\n",
        "  selected_cols = []\n",
        "  ch = 0\n",
        "  while len(selected_cols) < len(cols):\n",
        "    best = (0, None)\n",
        "    for i in cols:\n",
        "      t =[i]\n",
        "      if i in selected_cols:\n",
        "        continue\n",
        "      X = data.iloc[:, i:i+1]\n",
        "      for j in selected_cols:\n",
        "        X = pd.concat([X, data.iloc[:, j:j+1]], axis=1)\n",
        "        t.append(j)\n",
        "      X = X.values\n",
        "      y = data.iloc[:, :1].values\n",
        "      acc = get_accuracy(X, y)\n",
        "      print('The accuracy selecting '+str(t) +' items is '+ str(acc)+'%')\n",
        "      if acc > best[0]:\n",
        "        best = (acc, i)\n",
        "    selected_cols.append(best[1])\n",
        "    print('Adding '+str(best[1]) +' to selected features the accuracy is '+str(best[0])+'%')\n",
        "    if best[0]>absolute_best[0]:\n",
        "      absolute_best = (best[0], copy.deepcopy(selected_cols))\n",
        "    elif ch==0:\n",
        "      ch = 1\n",
        "      print('The accuracy is not increasing, continuing search anyway in case of local maxima.')\n",
        "  print('The highest accuracy of '+ str(absolute_best[0])+ '% is observed with '+str(absolute_best[1])+' elements.')"
      ],
      "metadata": {
        "id": "xawUWHyfRurf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_elimination(data):\n",
        "  cols = [i for i in range(1, len(data.columns))]\n",
        "  absolute_best = (0,None)\n",
        "  selected_cols = copy.deepcopy(cols)\n",
        "  removed_cols =[]\n",
        "  ch = 0\n",
        "  while len(selected_cols) != 0:\n",
        "    best = (0, None)\n",
        "    for i in cols:\n",
        "      if i in removed_cols:\n",
        "        continue\n",
        "      t = []\n",
        "      X = data.iloc[:, i:i]\n",
        "      for j in selected_cols:\n",
        "        if j!=i:\n",
        "          t.append(j)\n",
        "          X = pd.concat([X, data.iloc[:, j:j+1]], axis=1)\n",
        "      X = X.values\n",
        "      y = data.iloc[:, :1].values\n",
        "      acc = get_accuracy(X, y)\n",
        "      print('The accuracy with '+str(t) +' items is '+ str(acc)+'%')\n",
        "      if acc > best[0]:\n",
        "        best = (acc, i)\n",
        "    selected_cols.remove(best[1])\n",
        "    removed_cols.append(best[1])\n",
        "    print('Removing '+str(best[1])+' the highest accuracy of '+str(best[0])+'%')\n",
        "    if best[0]>absolute_best[0]:\n",
        "      absolute_best = (best[0], copy.deepcopy(selected_cols))\n",
        "    elif ch==0:\n",
        "      ch = 1\n",
        "      print('The accuracy is not increasing, continuing search anyway in case of local maxima.')\n",
        "  print('The highest accuracy of '+ str(absolute_best[0])+ '% is observed with '+str(absolute_best[1])+' elements.')"
      ],
      "metadata": {
        "id": "vp5SZ9jNP13C"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Welcome to Achala\\'s Feature Selection Algorithm')\n",
        "exitch = 0\n",
        "while exitch ==0:\n",
        "  print('---------------------------------------------------------------------------------------------------------------------')\n",
        "  print('Select one of the dataset options:')\n",
        "  print('1. Small dataset (CS205_small_Data_39)')\n",
        "  print('2. Large dataset (CS205_large_Data_45)')\n",
        "  print('3. Exit Program')\n",
        "  datach = int(input())\n",
        "  if datach == 1:\n",
        "    data = pd.read_csv('CS205_small_Data__39.txt', sep='  ', header=None, engine='python')\n",
        "  elif datach == 2:\n",
        "    data = pd.read_csv('CS205_large_Data__45.txt', sep='  ', header=None, engine='python')\n",
        "  elif datach == 3:\n",
        "    exitch = 1\n",
        "    continue\n",
        "  else:\n",
        "    print('Invalid input')\n",
        "    continue\n",
        "\n",
        "  print('Select one of the following options:')\n",
        "  print('1. Forward Selection')\n",
        "  print('2. Backward Elimination')\n",
        "  print('3. Exit Program')\n",
        "  selch = int(input())\n",
        "\n",
        "  print('Starting Feature Selection algorithm with the below configurations:')\n",
        "  if datach == 1:\n",
        "    print('1. Small dataset '+str(data.shape[0])+' samples and '+str(data.shape[1]-1)+' features')\n",
        "  elif datach == 2:\n",
        "    print('2. Large dataset '+str(data.shape[0])+' samples and '+str(data.shape[1]-1)+' features')\n",
        "\n",
        "  if selch == 1:\n",
        "    print('2. Forward Selection')\n",
        "    start = time.time()\n",
        "    forward_selection(data)\n",
        "    end = time.time()\n",
        "    print('Execution time: '+str(round((end-start), 2))+' seconds')\n",
        "  elif selch == 2:\n",
        "    start = time.time()\n",
        "    print('2. Forward Elimination')\n",
        "    backward_elimination(data)\n",
        "    end = time.time()\n",
        "    print('Execution time: '+str(round((end-start), 2))+ ' seconds')\n",
        "  elif selch == 3:\n",
        "    exitch = 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_jdqK3zjya0",
        "outputId": "72b55519-61ef-47c7-9f3c-fff619ae8c8b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to Achala's Feature Selection Algorithm\n",
            "Select one of the dataset options:\n",
            "1. Small dataset (CS205_small_Data_39)\n",
            "2. Large dataset (CS205_large_Data_45)\n",
            "3. Exit Program\n",
            "1\n",
            "Select one of the following options:\n",
            "1. Forward Selection\n",
            "2. Backward Elimination\n",
            "3. Exit Program\n",
            "1\n",
            "Starting Feature Selection algorithm with the below configurations:\n",
            "1. Small dataset 500 samples and 12 features\n",
            "2. Forward Selection\n",
            "The accuracy selecting [1] items is 68.4%\n",
            "The accuracy selecting [2] items is 70.8%\n",
            "The accuracy selecting [3] items is 72.0%\n",
            "The accuracy selecting [4] items is 76.2%\n",
            "The accuracy selecting [5] items is 75.6%\n",
            "The accuracy selecting [6] items is 82.4%\n",
            "The accuracy selecting [7] items is 72.8%\n",
            "The accuracy selecting [8] items is 71.0%\n",
            "The accuracy selecting [9] items is 73.4%\n",
            "The accuracy selecting [10] items is 71.4%\n",
            "The accuracy selecting [11] items is 72.2%\n",
            "The accuracy selecting [12] items is 71.2%\n",
            "Adding 6 to selected features the accuracy is 82.4%\n",
            "The accuracy selecting [1, 6] items is 79.8%\n",
            "The accuracy selecting [2, 6] items is 79.4%\n",
            "The accuracy selecting [3, 6] items is 81.6%\n",
            "The accuracy selecting [4, 6] items is 81.4%\n",
            "The accuracy selecting [5, 6] items is 80.8%\n",
            "The accuracy selecting [7, 6] items is 86.6%\n",
            "The accuracy selecting [8, 6] items is 83.2%\n",
            "The accuracy selecting [9, 6] items is 93.4%\n",
            "The accuracy selecting [10, 6] items is 81.0%\n",
            "The accuracy selecting [11, 6] items is 82.2%\n",
            "The accuracy selecting [12, 6] items is 82.2%\n",
            "Adding 9 to selected features the accuracy is 93.4%\n",
            "The accuracy selecting [1, 6, 9] items is 89.0%\n",
            "The accuracy selecting [2, 6, 9] items is 89.8%\n",
            "The accuracy selecting [3, 6, 9] items is 92.0%\n",
            "The accuracy selecting [4, 6, 9] items is 89.6%\n",
            "The accuracy selecting [5, 6, 9] items is 90.8%\n",
            "The accuracy selecting [7, 6, 9] items is 94.0%\n",
            "The accuracy selecting [8, 6, 9] items is 90.2%\n",
            "The accuracy selecting [10, 6, 9] items is 88.6%\n",
            "The accuracy selecting [11, 6, 9] items is 88.6%\n",
            "The accuracy selecting [12, 6, 9] items is 91.4%\n",
            "Adding 7 to selected features the accuracy is 94.0%\n",
            "The accuracy selecting [1, 6, 9, 7] items is 87.4%\n",
            "The accuracy selecting [2, 6, 9, 7] items is 85.8%\n",
            "The accuracy selecting [3, 6, 9, 7] items is 88.4%\n",
            "The accuracy selecting [4, 6, 9, 7] items is 87.4%\n",
            "The accuracy selecting [5, 6, 9, 7] items is 90.6%\n",
            "The accuracy selecting [8, 6, 9, 7] items is 87.4%\n",
            "The accuracy selecting [10, 6, 9, 7] items is 86.6%\n",
            "The accuracy selecting [11, 6, 9, 7] items is 89.6%\n",
            "The accuracy selecting [12, 6, 9, 7] items is 91.0%\n",
            "Adding 12 to selected features the accuracy is 91.0%\n",
            "The accuracy is not increasing, continuing search anyway in case of local maxima.\n",
            "The accuracy selecting [1, 6, 9, 7, 12] items is 83.4%\n",
            "The accuracy selecting [2, 6, 9, 7, 12] items is 83.2%\n",
            "The accuracy selecting [3, 6, 9, 7, 12] items is 85.6%\n",
            "The accuracy selecting [4, 6, 9, 7, 12] items is 84.4%\n",
            "The accuracy selecting [5, 6, 9, 7, 12] items is 84.6%\n",
            "The accuracy selecting [8, 6, 9, 7, 12] items is 84.2%\n",
            "The accuracy selecting [10, 6, 9, 7, 12] items is 84.4%\n",
            "The accuracy selecting [11, 6, 9, 7, 12] items is 85.0%\n",
            "Adding 3 to selected features the accuracy is 85.6%\n",
            "The accuracy selecting [1, 6, 9, 7, 12, 3] items is 78.2%\n",
            "The accuracy selecting [2, 6, 9, 7, 12, 3] items is 82.0%\n",
            "The accuracy selecting [4, 6, 9, 7, 12, 3] items is 79.8%\n",
            "The accuracy selecting [5, 6, 9, 7, 12, 3] items is 81.0%\n",
            "The accuracy selecting [8, 6, 9, 7, 12, 3] items is 81.0%\n",
            "The accuracy selecting [10, 6, 9, 7, 12, 3] items is 83.6%\n",
            "The accuracy selecting [11, 6, 9, 7, 12, 3] items is 83.0%\n",
            "Adding 10 to selected features the accuracy is 83.6%\n",
            "The accuracy selecting [1, 6, 9, 7, 12, 3, 10] items is 77.8%\n",
            "The accuracy selecting [2, 6, 9, 7, 12, 3, 10] items is 79.8%\n",
            "The accuracy selecting [4, 6, 9, 7, 12, 3, 10] items is 79.2%\n",
            "The accuracy selecting [5, 6, 9, 7, 12, 3, 10] items is 81.2%\n",
            "The accuracy selecting [8, 6, 9, 7, 12, 3, 10] items is 80.4%\n",
            "The accuracy selecting [11, 6, 9, 7, 12, 3, 10] items is 80.6%\n",
            "Adding 5 to selected features the accuracy is 81.2%\n",
            "The accuracy selecting [1, 6, 9, 7, 12, 3, 10, 5] items is 78.8%\n",
            "The accuracy selecting [2, 6, 9, 7, 12, 3, 10, 5] items is 76.6%\n",
            "The accuracy selecting [4, 6, 9, 7, 12, 3, 10, 5] items is 78.8%\n",
            "The accuracy selecting [8, 6, 9, 7, 12, 3, 10, 5] items is 78.2%\n",
            "The accuracy selecting [11, 6, 9, 7, 12, 3, 10, 5] items is 78.4%\n",
            "Adding 1 to selected features the accuracy is 78.8%\n",
            "The accuracy selecting [2, 6, 9, 7, 12, 3, 10, 5, 1] items is 77.0%\n",
            "The accuracy selecting [4, 6, 9, 7, 12, 3, 10, 5, 1] items is 76.6%\n",
            "The accuracy selecting [8, 6, 9, 7, 12, 3, 10, 5, 1] items is 75.8%\n",
            "The accuracy selecting [11, 6, 9, 7, 12, 3, 10, 5, 1] items is 77.2%\n",
            "Adding 11 to selected features the accuracy is 77.2%\n",
            "The accuracy selecting [2, 6, 9, 7, 12, 3, 10, 5, 1, 11] items is 77.6%\n",
            "The accuracy selecting [4, 6, 9, 7, 12, 3, 10, 5, 1, 11] items is 78.4%\n",
            "The accuracy selecting [8, 6, 9, 7, 12, 3, 10, 5, 1, 11] items is 74.4%\n",
            "Adding 4 to selected features the accuracy is 78.4%\n",
            "The accuracy selecting [2, 6, 9, 7, 12, 3, 10, 5, 1, 11, 4] items is 77.0%\n",
            "The accuracy selecting [8, 6, 9, 7, 12, 3, 10, 5, 1, 11, 4] items is 71.2%\n",
            "Adding 2 to selected features the accuracy is 77.0%\n",
            "The accuracy selecting [8, 6, 9, 7, 12, 3, 10, 5, 1, 11, 4, 2] items is 75.6%\n",
            "Adding 8 to selected features the accuracy is 75.6%\n",
            "The highest accuracy of 94.0% is observed with [6, 9, 7] elements.\n",
            "Execution time: 105.86 seconds\n",
            "Select one of the dataset options:\n",
            "1. Small dataset (CS205_small_Data_39)\n",
            "2. Large dataset (CS205_large_Data_45)\n",
            "3. Exit Program\n",
            "1\n",
            "Select one of the following options:\n",
            "1. Forward Selection\n",
            "2. Backward Elimination\n",
            "3. Exit Program\n",
            "2\n",
            "Starting Feature Selection algorithm with the below configurations:\n",
            "1. Small dataset 500 samples and 12 features\n",
            "2. Forward Elimination\n",
            "The accuracy with [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] items is 74.2%\n",
            "The accuracy with [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] items is 71.2%\n",
            "The accuracy with [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] items is 75.0%\n",
            "The accuracy with [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12] items is 75.0%\n",
            "The accuracy with [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12] items is 74.6%\n",
            "The accuracy with [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12] items is 72.4%\n",
            "The accuracy with [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12] items is 72.8%\n",
            "The accuracy with [1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12] items is 77.0%\n",
            "The accuracy with [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12] items is 74.6%\n",
            "The accuracy with [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12] items is 75.2%\n",
            "The accuracy with [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12] items is 74.8%\n",
            "The accuracy with [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11] items is 73.6%\n",
            "Removing 8 the highest accuracy of 77.0%\n",
            "The accuracy with [2, 3, 4, 5, 6, 7, 9, 10, 11, 12] items is 76.0%\n",
            "The accuracy with [1, 3, 4, 5, 6, 7, 9, 10, 11, 12] items is 78.4%\n",
            "The accuracy with [1, 2, 4, 5, 6, 7, 9, 10, 11, 12] items is 75.4%\n",
            "The accuracy with [1, 2, 3, 5, 6, 7, 9, 10, 11, 12] items is 77.6%\n",
            "The accuracy with [1, 2, 3, 4, 6, 7, 9, 10, 11, 12] items is 76.0%\n",
            "The accuracy with [1, 2, 3, 4, 5, 7, 9, 10, 11, 12] items is 74.0%\n",
            "The accuracy with [1, 2, 3, 4, 5, 6, 9, 10, 11, 12] items is 77.8%\n",
            "The accuracy with [1, 2, 3, 4, 5, 6, 7, 10, 11, 12] items is 76.0%\n",
            "The accuracy with [1, 2, 3, 4, 5, 6, 7, 9, 11, 12] items is 75.4%\n",
            "The accuracy with [1, 2, 3, 4, 5, 6, 7, 9, 10, 12] items is 75.2%\n",
            "The accuracy with [1, 2, 3, 4, 5, 6, 7, 9, 10, 11] items is 77.8%\n",
            "Removing 2 the highest accuracy of 78.4%\n",
            "The accuracy with [3, 4, 5, 6, 7, 9, 10, 11, 12] items is 76.6%\n",
            "The accuracy with [1, 4, 5, 6, 7, 9, 10, 11, 12] items is 78.2%\n",
            "The accuracy with [1, 3, 5, 6, 7, 9, 10, 11, 12] items is 77.2%\n",
            "The accuracy with [1, 3, 4, 6, 7, 9, 10, 11, 12] items is 77.0%\n",
            "The accuracy with [1, 3, 4, 5, 7, 9, 10, 11, 12] items is 74.6%\n",
            "The accuracy with [1, 3, 4, 5, 6, 9, 10, 11, 12] items is 79.8%\n",
            "The accuracy with [1, 3, 4, 5, 6, 7, 10, 11, 12] items is 75.4%\n",
            "The accuracy with [1, 3, 4, 5, 6, 7, 9, 11, 12] items is 78.6%\n",
            "The accuracy with [1, 3, 4, 5, 6, 7, 9, 10, 12] items is 76.6%\n",
            "The accuracy with [1, 3, 4, 5, 6, 7, 9, 10, 11] items is 77.4%\n",
            "Removing 7 the highest accuracy of 79.8%\n",
            "The accuracy with [3, 4, 5, 6, 9, 10, 11, 12] items is 80.4%\n",
            "The accuracy with [1, 4, 5, 6, 9, 10, 11, 12] items is 82.4%\n",
            "The accuracy with [1, 3, 5, 6, 9, 10, 11, 12] items is 81.6%\n",
            "The accuracy with [1, 3, 4, 6, 9, 10, 11, 12] items is 80.0%\n",
            "The accuracy with [1, 3, 4, 5, 9, 10, 11, 12] items is 74.0%\n",
            "The accuracy with [1, 3, 4, 5, 6, 10, 11, 12] items is 79.0%\n",
            "The accuracy with [1, 3, 4, 5, 6, 9, 11, 12] items is 80.4%\n",
            "The accuracy with [1, 3, 4, 5, 6, 9, 10, 12] items is 77.0%\n",
            "The accuracy with [1, 3, 4, 5, 6, 9, 10, 11] items is 78.0%\n",
            "Removing 3 the highest accuracy of 82.4%\n",
            "The accuracy with [4, 5, 6, 9, 10, 11, 12] items is 80.6%\n",
            "The accuracy with [1, 5, 6, 9, 10, 11, 12] items is 83.4%\n",
            "The accuracy with [1, 4, 6, 9, 10, 11, 12] items is 81.8%\n",
            "The accuracy with [1, 4, 5, 9, 10, 11, 12] items is 74.8%\n",
            "The accuracy with [1, 4, 5, 6, 10, 11, 12] items is 80.2%\n",
            "The accuracy with [1, 4, 5, 6, 9, 11, 12] items is 82.8%\n",
            "The accuracy with [1, 4, 5, 6, 9, 10, 12] items is 77.0%\n",
            "The accuracy with [1, 4, 5, 6, 9, 10, 11] items is 81.4%\n",
            "Removing 4 the highest accuracy of 83.4%\n",
            "The accuracy with [5, 6, 9, 10, 11, 12] items is 82.0%\n",
            "The accuracy with [1, 6, 9, 10, 11, 12] items is 82.8%\n",
            "The accuracy with [1, 5, 9, 10, 11, 12] items is 76.2%\n",
            "The accuracy with [1, 5, 6, 10, 11, 12] items is 81.4%\n",
            "The accuracy with [1, 5, 6, 9, 11, 12] items is 83.2%\n",
            "The accuracy with [1, 5, 6, 9, 10, 12] items is 81.6%\n",
            "The accuracy with [1, 5, 6, 9, 10, 11] items is 84.4%\n",
            "Removing 12 the highest accuracy of 84.4%\n",
            "The accuracy with [5, 6, 9, 10, 11] items is 84.8%\n",
            "The accuracy with [1, 6, 9, 10, 11] items is 83.4%\n",
            "The accuracy with [1, 5, 9, 10, 11] items is 76.8%\n",
            "The accuracy with [1, 5, 6, 10, 11] items is 80.2%\n",
            "The accuracy with [1, 5, 6, 9, 11] items is 85.8%\n",
            "The accuracy with [1, 5, 6, 9, 10] items is 83.2%\n",
            "Removing 10 the highest accuracy of 85.8%\n",
            "The accuracy with [5, 6, 9, 11] items is 88.2%\n",
            "The accuracy with [1, 6, 9, 11] items is 85.4%\n",
            "The accuracy with [1, 5, 9, 11] items is 74.0%\n",
            "The accuracy with [1, 5, 6, 11] items is 81.0%\n",
            "The accuracy with [1, 5, 6, 9] items is 82.6%\n",
            "Removing 1 the highest accuracy of 88.2%\n",
            "The accuracy with [6, 9, 11] items is 88.6%\n",
            "The accuracy with [5, 9, 11] items is 75.4%\n",
            "The accuracy with [5, 6, 11] items is 81.4%\n",
            "The accuracy with [5, 6, 9] items is 90.8%\n",
            "Removing 11 the highest accuracy of 90.8%\n",
            "The accuracy with [6, 9] items is 93.4%\n",
            "The accuracy with [5, 9] items is 76.8%\n",
            "The accuracy with [5, 6] items is 80.8%\n",
            "Removing 5 the highest accuracy of 93.4%\n",
            "The accuracy with [9] items is 73.4%\n",
            "The accuracy with [6] items is 82.4%\n",
            "Removing 9 the highest accuracy of 82.4%\n",
            "The accuracy is not increasing, continuing search anyway in case of local maxima.\n",
            "The accuracy with [] items is 17.2%\n",
            "Removing 6 the highest accuracy of 17.2%\n",
            "The highest accuracy of 93.4% is observed with [6, 9] elements.\n",
            "Execution time: 136.54 seconds\n",
            "Select one of the dataset options:\n",
            "1. Small dataset (CS205_small_Data_39)\n",
            "2. Large dataset (CS205_large_Data_45)\n",
            "3. Exit Program\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrBdh5T_frsf",
        "outputId": "9a40b6c4-ea7c-48a5-eebc-c07046320cc4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Small dataset 500 rows and 13 columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V61xCSkLpxM6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}